{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-03T21:51:38.475923Z","iopub.execute_input":"2025-03-03T21:51:38.476089Z","iopub.status.idle":"2025-03-03T21:51:38.479067Z","shell.execute_reply.started":"2025-03-03T21:51:38.476073Z","shell.execute_reply":"2025-03-03T21:51:38.478422Z"},"id":"G_U6PqupXylX","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# A Simple Starter Code for the AJL Competition\n\n@Cindy Deng\n\n---\n\n\nHi! This starter code is designed to help you get familiar with basic Kaggle operations and guide you through the basic workflow of a machine learning project.\n\nThe code outlines essential steps including data loading, preprocessing, model building, training, and generating predictions. Each section serves as a foundation, but there are many ways to enhance each step to improve your final model's accuracy. Feel free to experiment with different data augmentation techniques, model architectures, and tuning methods to optimize your final results! Some amazing tutorials are available through your AI Studio course in Canvas / in the 'Resource' section of this Kaggle competition.\n\nGood luck and have fun!\n\n---","metadata":{"id":"ULKHeEKpXyla"}},{"cell_type":"markdown","source":"## Note - About file path\n\nYou could use the cell above to print the names of the file directories and get the following directories:\n\n```\n/kaggle/input/bttai-ajl-2025/sample_submission.csv\n/kaggle/input/bttai-ajl-2025/train.csv\n/kaggle/input/bttai-ajl-2025/test.csv\n/kaggle/input/bttai-ajl-2025/test/test/e0374ae6c1362ff183cfba28ded5421b.jpg\n/kaggle/input/bttai-ajl-2025/test/test/437159c605260bdd079af230566af291.jpg\n...\n...\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/11271bdf2598afdd4260db3125e1f6a5.jpg\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/732819951dcf2b53d15ea7b8bb123b71.jpg\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/6dcc7a8abb5e1c6e670101f4b6231246.jpg\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/e63c3b3f0ab8905e204fe467cc7411f9.jpg\n...\n...\n```\n\n","metadata":{"id":"r7df1hzgXylc"}},{"cell_type":"markdown","source":"## 1. Import Necessary Libraries","metadata":{"id":"xaSbl3gPXylc"}},{"cell_type":"code","source":"# 1. Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n#Data augmentation:\nimport random\nfrom tqdm import tqdm\nfrom PIL import Image, ImageEnhance, ImageFilter\n# Explanation:\n# - pandas and numpy: for data manipulation\n# - sklearn: for splitting data and encoding labels\n# - tensorflow.keras: for building and training the neural network","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:38.479978Z","iopub.execute_input":"2025-03-03T21:51:38.480304Z","iopub.status.idle":"2025-03-03T21:51:51.868478Z","shell.execute_reply.started":"2025-03-03T21:51:38.480279Z","shell.execute_reply":"2025-03-03T21:51:51.867349Z"},"id":"blkk829wXyld","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Load Data\n\nMake sure to verify the file paths if you're running on a different platform.","metadata":{"id":"vTCVA6tfXyld"}},{"cell_type":"code","source":"# 2. Load Data\ntrain_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\n\n# Add .jpg extension to md5hash column to reference the file_name\ntrain_df['md5hash'] = train_df['md5hash'].astype(str) + '.jpg'\ntest_df['md5hash'] = test_df['md5hash'].astype(str) + '.jpg'\n\n# Combine label and md5hash to form the correct path\ntrain_df['file_path'] = train_df['label'] + '/' + train_df['md5hash']","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:51.869337Z","iopub.execute_input":"2025-03-03T21:51:51.869795Z","iopub.status.idle":"2025-03-03T21:51:51.911372Z","shell.execute_reply.started":"2025-03-03T21:51:51.86977Z","shell.execute_reply":"2025-03-03T21:51:51.910627Z"},"id":"gQvrwy9OXyle","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the first few rows to understand the structure\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:51.912045Z","iopub.execute_input":"2025-03-03T21:51:51.912308Z","iopub.status.idle":"2025-03-03T21:51:51.946672Z","shell.execute_reply.started":"2025-03-03T21:51:51.912288Z","shell.execute_reply":"2025-03-03T21:51:51.945744Z"},"id":"OuwDrj7aXyle","outputId":"1c39d024-6cd5-42a3-b9ae-31d7a446b496","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['label'].nunique() #amount of unique labels","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:51.947707Z","iopub.execute_input":"2025-03-03T21:51:51.947988Z","iopub.status.idle":"2025-03-03T21:51:51.959284Z","shell.execute_reply.started":"2025-03-03T21:51:51.94796Z","shell.execute_reply":"2025-03-03T21:51:51.95842Z"},"id":"Zpz6M-QiXylg","outputId":"cfc822c9-895c-4e17-df5b-00796b8d3757","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#counting the amount of each skin tone on the FST assigned by centur lab\nsize = train_df.shape[0]\nprint(size)\n#fitzpatrick_centaur rating\nprint(train_df[\"fitzpatrick_centaur\"].nunique())\nprint(train_df[\"fitzpatrick_centaur\"].unique())\n#fitzpatrick_scale rating\nprint(train_df[\"fitzpatrick_scale\"].nunique())\nprint(train_df[\"fitzpatrick_scale\"].unique())","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:51.961523Z","iopub.execute_input":"2025-03-03T21:51:51.961763Z","iopub.status.idle":"2025-03-03T21:51:51.980718Z","shell.execute_reply.started":"2025-03-03T21:51:51.961746Z","shell.execute_reply":"2025-03-03T21:51:51.980021Z"},"id":"ioK9yFNKXylg","outputId":"473e26b1-1629-49cb-a36d-87d998b839ef","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print((train_df[\"fitzpatrick_centaur\"]!=train_df[\"fitzpatrick_scale\"]).sum())\nmismatch = (train_df[\"fitzpatrick_centaur\"]!=train_df[\"fitzpatrick_scale\"]).sum()\nprint(\"percent of discrepencies between self perscribed skin shade and centur lab perscribes skine shade:\", mismatch/size * 100,\"%\")","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:51.982088Z","iopub.execute_input":"2025-03-03T21:51:51.982374Z","iopub.status.idle":"2025-03-03T21:51:51.999135Z","shell.execute_reply.started":"2025-03-03T21:51:51.982354Z","shell.execute_reply":"2025-03-03T21:51:51.998286Z"},"id":"htS2dbPoXylg","outputId":"3a1a73f4-0a15-45c5-91b4-844f01cb4766","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# phase -1 in fitzpatrick_centaur\nneg_one = (train_df[\"fitzpatrick_centaur\"]==-1).sum()\nprint(\"amount of -1:\",neg_one)\nprint(\"percentage of -1:\", neg_one/size * 100,\"%\")","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:51.999898Z","iopub.execute_input":"2025-03-03T21:51:52.000119Z","iopub.status.idle":"2025-03-03T21:51:52.005839Z","shell.execute_reply.started":"2025-03-03T21:51:52.0001Z","shell.execute_reply":"2025-03-03T21:51:52.004943Z"},"id":"ujFWwhAyXylh","outputId":"cb4ca063-4764-4516-e501-3f2e24ad6214","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#there are some elements that are not labeled in the centaur label but are in the self determined scale\n#could I create a new one and try and populate this???\nprint(((train_df[\"fitzpatrick_centaur\"]==-1) & ( train_df[\"fitzpatrick_scale\"]!=-1)).sum())","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.006524Z","iopub.execute_input":"2025-03-03T21:51:52.006759Z","iopub.status.idle":"2025-03-03T21:51:52.021849Z","shell.execute_reply.started":"2025-03-03T21:51:52.00674Z","shell.execute_reply":"2025-03-03T21:51:52.021143Z"},"id":"Ctd2M96uXylh","outputId":"52231374-f9a8-484e-8e4c-5f7cecbc7756","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# phase 1 in fitzpatrick_centaur\none = (train_df[\"fitzpatrick_centaur\"]==1).sum()\nprint(\"amount of 1:\",one)\nprint(\"percentage of 1:\", one/size * 100,\"%\")","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.022547Z","iopub.execute_input":"2025-03-03T21:51:52.022762Z","iopub.status.idle":"2025-03-03T21:51:52.034293Z","shell.execute_reply.started":"2025-03-03T21:51:52.022742Z","shell.execute_reply":"2025-03-03T21:51:52.033657Z"},"id":"a05kzYSSXylh","outputId":"e111a9cb-c59d-47ff-83ea-4e243a1a5485","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# phase 2 in fitzpatrick_centaur\ntwo = (train_df[\"fitzpatrick_centaur\"]==2).sum()\nprint(\"amount of 2:\",two)\nprint(\"percentage of 2:\", two/size * 100,\"%\")\nprint(\"additions 2 need to match 1:\", one - two)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.034945Z","iopub.execute_input":"2025-03-03T21:51:52.035199Z","iopub.status.idle":"2025-03-03T21:51:52.048172Z","shell.execute_reply.started":"2025-03-03T21:51:52.035177Z","shell.execute_reply":"2025-03-03T21:51:52.047336Z"},"id":"r7EHUlRlXyli","outputId":"7eac3112-8667-4d60-9cea-622ee9d3ccd1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# phase 3 in fitzpatrick_centaur\nthree = (train_df[\"fitzpatrick_centaur\"]==3).sum()\nprint(\"amount of 3 :\",three)\nprint(\"percentage of 3:\", three/size * 100,\"%\")\nprint(\"additions 3 need to match 1:\", one - three)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.04891Z","iopub.execute_input":"2025-03-03T21:51:52.049142Z","iopub.status.idle":"2025-03-03T21:51:52.066299Z","shell.execute_reply.started":"2025-03-03T21:51:52.049124Z","shell.execute_reply":"2025-03-03T21:51:52.065614Z"},"id":"2sHFKKQsXyli","outputId":"35ccc93c-3384-4594-c8d9-249ee066a4d0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# phase 4 in fitzpatrick_centaur\nfour = (train_df[\"fitzpatrick_centaur\"]==4).sum()\nprint(\"amount of 4:\",four)\nprint(\"percentage of 4:\", four/size * 100,\"%\")\nprint(\"additions 4 need to match 1:\", one - four)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.067066Z","iopub.execute_input":"2025-03-03T21:51:52.067274Z","iopub.status.idle":"2025-03-03T21:51:52.078766Z","shell.execute_reply.started":"2025-03-03T21:51:52.067255Z","shell.execute_reply":"2025-03-03T21:51:52.077942Z"},"id":"w4CEq3MAXyli","outputId":"8c2bbbc4-8a97-476d-d320-499c095c6753","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# phase 5 in fitzpatrick_centaur\nfive = (train_df[\"fitzpatrick_centaur\"]==5).sum()\nprint(\"amount of 5:\",five)\nprint(\"percentage of 5:\", five/size * 100,\"%\")\nprint(\"additions 5 need to match 1:\", one - five)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.079542Z","iopub.execute_input":"2025-03-03T21:51:52.079835Z","iopub.status.idle":"2025-03-03T21:51:52.093337Z","shell.execute_reply.started":"2025-03-03T21:51:52.079814Z","shell.execute_reply":"2025-03-03T21:51:52.092628Z"},"id":"MC848YXiXyli","outputId":"9e52d676-332a-445b-d2fa-43ae652ff645","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"six = (train_df[\"fitzpatrick_centaur\"]==6).sum()\nprint(\"amount of 6:\",six)\nprint(\"percentage of 5:\", six/size * 100,\"%\")\nprint(\"additions 5 need to match 1:\", one - six)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.093947Z","iopub.execute_input":"2025-03-03T21:51:52.094132Z","iopub.status.idle":"2025-03-03T21:51:52.108786Z","shell.execute_reply.started":"2025-03-03T21:51:52.094117Z","shell.execute_reply":"2025-03-03T21:51:52.108006Z"},"id":"MNtOkBJOXyli","outputId":"b58e0b49-4cf1-49fe-ca1a-d349e0852540","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counts = train_df[\"label\"].value_counts()\nprint(label_counts)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.109417Z","iopub.execute_input":"2025-03-03T21:51:52.109587Z","iopub.status.idle":"2025-03-03T21:51:52.125966Z","shell.execute_reply.started":"2025-03-03T21:51:52.10957Z","shell.execute_reply":"2025-03-03T21:51:52.125027Z"},"id":"ur2pKJ87Xyli","outputId":"2cd8c952-9743-44cc-8903-0bf35942f086","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Data Preprocessing\n\n\nThis section demonstrates basic preprocessing techniques. To enhance data quality and model performance, consider incorporating more advanced preprocessing methods.\n\nFor further guidance, feel free to take a look at the [Image Preprocessing tutorial](https://colab.research.google.com/drive/1-ItNcRMbZBE6BCwPT-wD8m3YmHqwHxme?usp=sharing)  available in the 'Resources' section of this Kaggle competition.\n","metadata":{"id":"aHbnpd53Xyli"}},{"cell_type":"code","source":"# 3. Data Preprocessing\n# Encode the labels\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n\n# Split the data into training and validation sets\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Define image data generators for training and validation\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Define the directory paths\ntrain_dir = '/kaggle/input/bttai-ajl-2025/train/train/'","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.126714Z","iopub.execute_input":"2025-03-03T21:51:52.12696Z","iopub.status.idle":"2025-03-03T21:51:52.148985Z","shell.execute_reply.started":"2025-03-03T21:51:52.126936Z","shell.execute_reply":"2025-03-03T21:51:52.148253Z"},"id":"RHE6fNMuXylj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_generator(dataframe, directory, batch_size=32, target_size=(128, 128)):\n    \"\"\"\n    Template function to create image generators.\n    Students should complete this function to load images and labels properly.\n    \"\"\"\n    # Fill in the correct flow_from_dataframe parameters\n    generator = train_datagen.flow_from_dataframe(\n        dataframe=dataframe,\n        directory=directory,\n        x_col='file_path',  # Use combined path\n        y_col='encoded_label',\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='raw',\n        validate_filenames=False  # Disable strict filename validation\n    )\n    return generator","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.149622Z","iopub.execute_input":"2025-03-03T21:51:52.14982Z","iopub.status.idle":"2025-03-03T21:51:52.154508Z","shell.execute_reply.started":"2025-03-03T21:51:52.149801Z","shell.execute_reply":"2025-03-03T21:51:52.153333Z"},"id":"N1n6CRDPXylj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create generators\ntrain_generator = create_generator(train_data, train_dir)\nval_generator = create_generator(val_data, train_dir)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.155187Z","iopub.execute_input":"2025-03-03T21:51:52.155442Z","iopub.status.idle":"2025-03-03T21:51:52.175964Z","shell.execute_reply.started":"2025-03-03T21:51:52.155423Z","shell.execute_reply":"2025-03-03T21:51:52.175245Z"},"id":"kY0udyxiXylj","outputId":"32e7405c-a781-470f-81d4-5ac6ec21908f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#taking a look at some of the photos\nimport matplotlib.pyplot as plt\nfile_name = train_df['md5hash'][0:3]\nfile_label = train_df['label'][0:3]\nfile_path = []\nimages = []\ntitles = []\nfor i in range(len(file_name)):\n    #getting path to the image\n    fn = os.path.splitext(file_name[i])[0] #without jpg\n    image_dir = train_dir+file_label[i]\n    images.append(Image.open(os.path.join(image_dir,file_name[i]))) #extracting the image\n    file_path.append(os.path.join(image_dir,file_name[i]))\n    #print(images)\n    title = file_label[i]\n    titles.append(title)\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\nfor i,ax in enumerate(axs):\n    ax.imshow(images[i])\n    ax.axis('off')  # Hide axes for better visual appeal\n    ax.set_title(titles[i])\nplt.tight_layout()\nplt.show();\nprint(file_path)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.17925Z","iopub.execute_input":"2025-03-03T21:51:52.179494Z","iopub.status.idle":"2025-03-03T21:51:52.777469Z","shell.execute_reply.started":"2025-03-03T21:51:52.179472Z","shell.execute_reply":"2025-03-03T21:51:52.776274Z"},"id":"cWWZrBROXylj","outputId":"f3a7ec70-92c3-4816-a624-09e2e2e651e9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rotate_image(image_path, angle = 180):\n    from PIL import Image, ImageEnhance, ImageFilter\n    image = Image.open(image_path)\n    return image.rotate(angle)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.778571Z","iopub.execute_input":"2025-03-03T21:51:52.778787Z","iopub.status.idle":"2025-03-03T21:51:52.782751Z","shell.execute_reply.started":"2025-03-03T21:51:52.778771Z","shell.execute_reply":"2025-03-03T21:51:52.781777Z"},"id":"3qHPneLhXylj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(images[1])\nax.axis('off')  # Hide axes for better visual appeal\nax.set_title(titles[1])\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.783577Z","iopub.execute_input":"2025-03-03T21:51:52.78379Z","iopub.status.idle":"2025-03-03T21:51:52.920464Z","shell.execute_reply.started":"2025-03-03T21:51:52.78377Z","shell.execute_reply":"2025-03-03T21:51:52.919507Z"},"id":"nfMxgur_Xylj","outputId":"3cccafab-8744-40fb-dea2-520fdb6ad0a0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augemented_image_1 = rotate_image(file_path[1])\nfig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(augemented_image_1)\nax.axis('off')  # Hide axes for better visual appeal\nax.set_title(titles[1])\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:52.921404Z","iopub.execute_input":"2025-03-03T21:51:52.92166Z","iopub.status.idle":"2025-03-03T21:51:53.052338Z","shell.execute_reply.started":"2025-03-03T21:51:52.921637Z","shell.execute_reply":"2025-03-03T21:51:53.051485Z"},"id":"5DjpfIzXXylj","outputId":"4d5d46a0-3b8e-4d56-9f66-e78bb4a4fec5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augemented_image_1 = images[2].filter(ImageFilter.GaussianBlur(radius=2))\nfig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(augemented_image_1)\nax.axis('off')  # Hide axes for better visual appeal\nax.set_title(titles[1])\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:53.05298Z","iopub.execute_input":"2025-03-03T21:51:53.053197Z","iopub.status.idle":"2025-03-03T21:51:53.223284Z","shell.execute_reply.started":"2025-03-03T21:51:53.053178Z","shell.execute_reply":"2025-03-03T21:51:53.222376Z"},"id":"MGIJXvWiXylk","outputId":"3b64399d-8e33-47f1-f222-e6d730ea71a9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image, ImageEnhance, ImageFilter","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:53.224156Z","iopub.execute_input":"2025-03-03T21:51:53.224469Z","iopub.status.idle":"2025-03-03T21:51:53.227726Z","shell.execute_reply.started":"2025-03-03T21:51:53.224437Z","shell.execute_reply":"2025-03-03T21:51:53.227091Z"},"id":"HXBNDkiGXylk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# rotate some twos so that their equal to ones\nfrom PIL import Image, ImageEnhance, ImageFilter\nimport os\nskin_two = train_df[train_df[\"fitzpatrick_centaur\"]==2]\n#print(skin_two)\nselected_rows = skin_two.sample(n=270, random_state = 42) #randomly select 270 images\nnew_entries = []  # Initialize the list before appending new rows\n#image_root = train_dir\nfor _ , row in selected_rows.iterrows():\n    #print(row)\n    fn = os.path.splitext(row[\"md5hash\"])[0]\n    image_dir = train_dir+ row[\"label\"]\n    original_path = os.path.join(image_dir,row[\"md5hash\"])\n    #print(original_path)\n    #try:\n        #img = Image.open(original_path)\n    img = Image.open(original_path)\n    rotate_image = img.rotate(180)\n    #rotate_image = rotate_image(original_path) #rotating image by 180 degree\n    output_dir = \"augmented_images\"\n    os.makedirs(output_dir, exist_ok = True)\n    new_md5hash = row['md5hash'].split('.')[0]+ \"_rot180.jpg\"\n    output_path = os.path.join(output_dir, new_md5hash)\n    rotate_image.save(output_path, format=\"JPEG\")  # Specify format explicitly\n\n    #adding to overall dataframe\n    new_row = row.copy()\n    new_row['md5hash'] = new_md5hash\n    new_entries.append(new_row)\nnew_entries_df = pd.DataFrame(new_entries)\ntrain_df = pd.concat([train_df, new_entries_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:53.228402Z","iopub.execute_input":"2025-03-03T21:51:53.228595Z","iopub.status.idle":"2025-03-03T21:51:55.807493Z","shell.execute_reply.started":"2025-03-03T21:51:53.228575Z","shell.execute_reply":"2025-03-03T21:51:55.806614Z"},"id":"tsK-0S6WXylk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"two = (train_df[\"fitzpatrick_centaur\"]==2).sum()\nprint(\"amount of 2:\",two)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:55.808177Z","iopub.execute_input":"2025-03-03T21:51:55.808444Z","iopub.status.idle":"2025-03-03T21:51:55.812992Z","shell.execute_reply.started":"2025-03-03T21:51:55.808422Z","shell.execute_reply":"2025-03-03T21:51:55.812181Z"},"id":"_J28j_gNXylk","outputId":"395bdd06-b70b-4059-8fa0-e99a24990e83","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image, ImageEnhance, ImageFilter\nimport os\nskin_three = train_df[train_df[\"fitzpatrick_centaur\"]==3]\nselected_rows = skin_three.sample(n=255, random_state = 42) #randomly select 255 images to rotat 90 and 180\nnew_entries = []  # Initialize the list before appending new rows\nfor _ , row in selected_rows.iterrows():\n    #print(row)\n    fn = os.path.splitext(row[\"md5hash\"])[0]\n    image_dir = train_dir+ row[\"label\"]\n    original_path = os.path.join(image_dir,row[\"md5hash\"])\n    img = Image.open(original_path)\n    rotate_image_180  = img.rotate(180)\n    rotate_image_90 = img.rotate(90)\n    output_dir = \"augmented_images\"\n    os.makedirs(output_dir, exist_ok = True)\n    new_md5hash_180 = row['md5hash'].split('.')[0]+ \"_rot180.jpg\"\n    new_md5hash_90 = row['md5hash'].split('.')[0]+ \"_rot90.jpg\"\n    output_path_180 = os.path.join(output_dir, new_md5hash_180)\n    output_path_90 = os.path.join(output_dir, new_md5hash_90)\n    rotate_image_180.save(output_path_180, format=\"JPEG\")  # Specify format explicitly\n    rotate_image_90.save(output_path_90, format=\"JPEG\")  # Specify format explicitly\n\n    #adding to overall dataframe\n    new_row = row.copy()\n    new_row['md5hash'] = new_md5hash_180\n    new_entries.append(new_row)\n    new_row['md5hash'] = new_md5hash_90\n    new_entries.append(new_row)\nnew_entries_df = pd.DataFrame(new_entries)\ntrain_df = pd.concat([train_df, new_entries_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:55.813765Z","iopub.execute_input":"2025-03-03T21:51:55.813989Z","iopub.status.idle":"2025-03-03T21:51:58.477342Z","shell.execute_reply.started":"2025-03-03T21:51:55.81397Z","shell.execute_reply":"2025-03-03T21:51:58.476591Z"},"id":"LSTjFy7AXylk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"three = (train_df[\"fitzpatrick_centaur\"]==3).sum()\nprint(\"amount of 3 :\",three)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:58.478001Z","iopub.execute_input":"2025-03-03T21:51:58.478166Z","iopub.status.idle":"2025-03-03T21:51:58.482695Z","shell.execute_reply.started":"2025-03-03T21:51:58.478151Z","shell.execute_reply":"2025-03-03T21:51:58.481893Z"},"id":"yCm9eW0cXylk","outputId":"3092a10d-5fb3-459d-d834-023537c7db6d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skin_four = train_df[train_df[\"fitzpatrick_centaur\"] == 4]\nselected_rows = skin_four.sample(n=253, random_state=42)  # Randomly select 255 images to rotate 90°, 180°, and 270°\nnew_entries = []  # Initialize the list before appending new rows\n\nfor _, row in selected_rows.iterrows():\n    # Get file paths\n    fn = os.path.splitext(row[\"md5hash\"])[0]\n    image_dir = train_dir + row[\"label\"]\n    original_path = os.path.join(image_dir, row[\"md5hash\"])\n    img = Image.open(original_path)\n\n    # Apply rotations\n    rotate_image_180 = img.rotate(180)\n    rotate_image_90 = img.rotate(90)\n    rotate_image_270 = img.rotate(270)  # Adding 270° rotation\n\n    # Set output directory\n    output_dir = \"augmented_images\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Save rotated images with new filenames\n    new_md5hash_180 = row['md5hash'].split('.')[0] + \"_rot180.jpg\"\n    new_md5hash_90 = row['md5hash'].split('.')[0] + \"_rot90.jpg\"\n    new_md5hash_270 = row['md5hash'].split('.')[0] + \"_rot270.jpg\"  # New filename for 270° rotation\n\n    output_path_180 = os.path.join(output_dir, new_md5hash_180)\n    output_path_90 = os.path.join(output_dir, new_md5hash_90)\n    output_path_270 = os.path.join(output_dir, new_md5hash_270)  # Output path for 270° image\n\n    rotate_image_180.save(output_path_180, format=\"JPEG\")  # Specify format explicitly\n    rotate_image_90.save(output_path_90, format=\"JPEG\")  # Specify format explicitly\n    rotate_image_270.save(output_path_270, format=\"JPEG\")  # Save the 270° rotated image\n\n    # Add new entries to overall dataframe\n    new_row = row.copy()\n    new_row['md5hash'] = new_md5hash_180\n    new_entries.append(new_row)\n\n    new_row['md5hash'] = new_md5hash_90\n    new_entries.append(new_row)\n\n    new_row['md5hash'] = new_md5hash_270  # Add 270° rotated image\n    new_entries.append(new_row)\n\n# Convert the new entries to a DataFrame and append it to the original DataFrame\nnew_entries_df = pd.DataFrame(new_entries)\ntrain_df = pd.concat([train_df, new_entries_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:51:58.483591Z","iopub.execute_input":"2025-03-03T21:51:58.483853Z","iopub.status.idle":"2025-03-03T21:52:02.160992Z","shell.execute_reply.started":"2025-03-03T21:51:58.483833Z","shell.execute_reply":"2025-03-03T21:52:02.160193Z"},"id":"sqh96xZPXylk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"four = (train_df[\"fitzpatrick_centaur\"]==4).sum()\nprint(\"amount of 4:\",four)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:52:02.161809Z","iopub.execute_input":"2025-03-03T21:52:02.162016Z","iopub.status.idle":"2025-03-03T21:52:02.166549Z","shell.execute_reply.started":"2025-03-03T21:52:02.161998Z","shell.execute_reply":"2025-03-03T21:52:02.16593Z"},"id":"OLo-vikFXyll","outputId":"8891de33-8d3d-4f05-9982-316a5e9d8a75","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skin_five = train_df[train_df[\"fitzpatrick_centaur\"] == 5]\nselected_rows = skin_five.sample(n=147, random_state=42)\nnew_entries = []  # Initialize the list before appending new rows\n\nshift_x = 20  # Shift 20 pixels horizontally\nshift_y = 20  # Shift 20 pixels vertically\n\nfor _, row in selected_rows.iterrows():\n    fn = os.path.splitext(row[\"md5hash\"])[0]\n    image_dir = os.path.join(train_dir, row[\"label\"])\n    original_path = os.path.join(image_dir, row[\"md5hash\"])\n\n    img = Image.open(original_path)\n\n    # Rotation by 90, 180, 270\n    rotate_image_90 = img.rotate(90)\n    rotate_image_180 = img.rotate(180)\n    rotate_image_270 = img.rotate(270)\n\n    # Apply Gaussian Blur\n    blurred_image = img.filter(ImageFilter.GaussianBlur(radius=2))  # Apply blur with a radius of 2\n\n    # Apply shift (translation)\n    shifted_image = img.transform(img.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y))  # Shift image by (shift_x, shift_y)\n\n    # Output directory\n    output_dir = \"augmented_images\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Saving the rotated, shifted, and blurred images\n    new_md5hash_90 = fn + \"_rot90.jpg\"\n    new_md5hash_180 = fn + \"_rot180.jpg\"\n    new_md5hash_270 = fn + \"_rot270.jpg\"\n    new_md5hash_blur = fn + \"_blur.jpg\"\n    new_md5hash_shift = fn + \"_shift.jpg\"\n\n    output_path_90 = os.path.join(output_dir, new_md5hash_90)\n    output_path_180 = os.path.join(output_dir, new_md5hash_180)\n    output_path_270 = os.path.join(output_dir, new_md5hash_270)\n    output_path_blur = os.path.join(output_dir, new_md5hash_blur)\n    output_path_shift = os.path.join(output_dir, new_md5hash_shift)\n\n    rotate_image_90.save(output_path_90, format=\"JPEG\")\n    rotate_image_180.save(output_path_180, format=\"JPEG\")\n    rotate_image_270.save(output_path_270, format=\"JPEG\")\n    blurred_image.save(output_path_blur, format=\"JPEG\")\n    shifted_image.save(output_path_shift, format=\"JPEG\")\n\n    # Adding to the overall dataframe\n    new_row_90 = row.copy()\n    new_row_90['md5hash'] = new_md5hash_90\n    new_entries.append(new_row_90)\n\n    new_row_180 = row.copy()\n    new_row_180['md5hash'] = new_md5hash_180\n    new_entries.append(new_row_180)\n\n    new_row_270 = row.copy()\n    new_row_270['md5hash'] = new_md5hash_270\n    new_entries.append(new_row_270)\n\n    new_row_blur = row.copy()\n    new_row_blur['md5hash'] = new_md5hash_blur\n    new_entries.append(new_row_blur)\n\n    new_row_shift = row.copy()\n    new_row_shift['md5hash'] = new_md5hash_shift\n    new_entries.append(new_row_shift)\n\n# Add the new augmented entries to the dataframe\nnew_entries_df = pd.DataFrame(new_entries)\ntrain_df = pd.concat([train_df, new_entries_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:52:02.167142Z","iopub.execute_input":"2025-03-03T21:52:02.167376Z","iopub.status.idle":"2025-03-03T21:52:07.322616Z","shell.execute_reply.started":"2025-03-03T21:52:02.16736Z","shell.execute_reply":"2025-03-03T21:52:07.321906Z"},"id":"VCyblUcPXyll","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"five = (train_df[\"fitzpatrick_centaur\"]==5).sum()\nprint(\"amount of 5:\",five)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:52:07.323265Z","iopub.execute_input":"2025-03-03T21:52:07.323426Z","iopub.status.idle":"2025-03-03T21:52:07.327831Z","shell.execute_reply.started":"2025-03-03T21:52:07.32341Z","shell.execute_reply":"2025-03-03T21:52:07.326619Z"},"id":"aMpN1SAnXyll","outputId":"36ff3757-55c7-4e3f-ba4f-fb45c7ede4e8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skin_six = train_df[train_df[\"fitzpatrick_centaur\"] == 6]\nselected_rows = skin_six.sample(n=80, random_state=42)  # Randomly select 80 images\nnew_entries = []  # Initialize the list before appending new rows\n\n# Define shift values (you can adjust this as needed)\nshift_x = 20  # Shift 20 pixels horizontally\nshift_y = 20  # Shift 20 pixels vertically\n\n# Define the number of augmentations needed per image\naugmentations_per_image = 12  # Average number of augmentations (since we need to get 1000 images)\n\nfor _, row in selected_rows.iterrows():\n    fn = os.path.splitext(row[\"md5hash\"])[0]\n    image_dir = os.path.join(train_dir, row[\"label\"])\n    original_path = os.path.join(image_dir, row[\"md5hash\"])\n\n    img = Image.open(original_path)\n\n    # Rotation by 90, 180, 270\n    rotate_image_90 = img.rotate(90)\n    rotate_image_180 = img.rotate(180)\n    rotate_image_270 = img.rotate(270)\n\n    # Save rotated images first\n    new_md5hash_90_rot = fn + f\"_rot90.jpg\"\n    new_md5hash_180_rot = fn + f\"_rot180.jpg\"\n    new_md5hash_270_rot = fn + f\"_rot270.jpg\"\n\n    output_dir = \"augmented_images\"\n    os.makedirs(output_dir, exist_ok=True)\n\n    output_path_90_rot = os.path.join(output_dir, new_md5hash_90_rot)\n    output_path_180_rot = os.path.join(output_dir, new_md5hash_180_rot)\n    output_path_270_rot = os.path.join(output_dir, new_md5hash_270_rot)\n\n    rotate_image_90.save(output_path_90_rot, format=\"JPEG\")\n    rotate_image_180.save(output_path_180_rot, format=\"JPEG\")\n    rotate_image_270.save(output_path_270_rot, format=\"JPEG\")\n\n    # Now apply Gaussian Blur to each rotated image\n    blurred_image_90 = rotate_image_90.filter(ImageFilter.GaussianBlur(radius=2))\n    blurred_image_180 = rotate_image_180.filter(ImageFilter.GaussianBlur(radius=2))\n    blurred_image_270 = rotate_image_270.filter(ImageFilter.GaussianBlur(radius=2))\n\n    # Save rotated + blurred images\n    new_md5hash_90_blur = fn + f\"_rot90_blur.jpg\"\n    new_md5hash_180_blur = fn + f\"_rot180_blur.jpg\"\n    new_md5hash_270_blur = fn + f\"_rot270_blur.jpg\"\n\n    output_path_90_blur = os.path.join(output_dir, new_md5hash_90_blur)\n    output_path_180_blur = os.path.join(output_dir, new_md5hash_180_blur)\n    output_path_270_blur = os.path.join(output_dir, new_md5hash_270_blur)\n\n    blurred_image_90.save(output_path_90_blur, format=\"JPEG\")\n    blurred_image_180.save(output_path_180_blur, format=\"JPEG\")\n    blurred_image_270.save(output_path_270_blur, format=\"JPEG\")\n\n    # Now apply shift (translation) to each blurred image\n    shifted_blurred_image_90 = blurred_image_90.transform(blurred_image_90.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y))\n    shifted_blurred_image_180 = blurred_image_180.transform(blurred_image_180.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y))\n    shifted_blurred_image_270 = blurred_image_270.transform(blurred_image_270.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y))\n\n    # Save rotated + blurred + shifted images\n    new_md5hash_90_blur_shift = fn + f\"_rot90_blur_shift.jpg\"\n    new_md5hash_180_blur_shift = fn + f\"_rot180_blur_shift.jpg\"\n    new_md5hash_270_blur_shift = fn + f\"_rot270_blur_shift.jpg\"\n\n    output_path_90_blur_shift = os.path.join(output_dir, new_md5hash_90_blur_shift)\n    output_path_180_blur_shift = os.path.join(output_dir, new_md5hash_180_blur_shift)\n    output_path_270_blur_shift = os.path.join(output_dir, new_md5hash_270_blur_shift)\n\n    shifted_blurred_image_90.save(output_path_90_blur_shift, format=\"JPEG\")\n    shifted_blurred_image_180.save(output_path_180_blur_shift, format=\"JPEG\")\n    shifted_blurred_image_270.save(output_path_270_blur_shift, format=\"JPEG\")\n\n    # Adding to the overall dataframe\n    new_row_90_rot = row.copy()\n    new_row_90_rot['md5hash'] = new_md5hash_90_rot\n    new_entries.append(new_row_90_rot)\n\n    new_row_180_rot = row.copy()\n    new_row_180_rot['md5hash'] = new_md5hash_180_rot\n    new_entries.append(new_row_180_rot)\n\n    new_row_270_rot = row.copy()\n    new_row_270_rot['md5hash'] = new_md5hash_270_rot\n    new_entries.append(new_row_270_rot)\n\n    new_row_90_blur = row.copy()\n    new_row_90_blur['md5hash'] = new_md5hash_90_blur\n    new_entries.append(new_row_90_blur)\n\n    new_row_180_blur = row.copy()\n    new_row_180_blur['md5hash'] = new_md5hash_180_blur\n    new_entries.append(new_row_180_blur)\n\n    new_row_270_blur = row.copy()\n    new_row_270_blur['md5hash'] = new_md5hash_270_blur\n    new_entries.append(new_row_270_blur)\n\n    new_row_90_blur_shift = row.copy()\n    new_row_90_blur_shift['md5hash'] = new_md5hash_90_blur_shift\n    new_entries.append(new_row_90_blur_shift)\n\n    new_row_180_blur_shift = row.copy()\n    new_row_180_blur_shift['md5hash'] = new_md5hash_180_blur_shift\n    new_entries.append(new_row_180_blur_shift)\n\n    new_row_270_blur_shift = row.copy()\n    new_row_270_blur_shift['md5hash'] = new_md5hash_270_blur_shift\n    new_entries.append(new_row_270_blur_shift)\n\n# Add the new augmented entries to the dataframe\nnew_entries_df = pd.DataFrame(new_entries)\ntrain_df = pd.concat([train_df, new_entries_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:52:07.328586Z","iopub.execute_input":"2025-03-03T21:52:07.328807Z","iopub.status.idle":"2025-03-03T21:52:16.350197Z","shell.execute_reply.started":"2025-03-03T21:52:07.328784Z","shell.execute_reply":"2025-03-03T21:52:16.349453Z"},"id":"G3UsQhd7Xyll","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"six = (train_df[\"fitzpatrick_centaur\"]== 6).sum()\nprint(\"amount of 6:\",six) #around the same amount but slightlty less","metadata":{"execution":{"iopub.status.busy":"2025-03-03T21:52:16.350888Z","iopub.execute_input":"2025-03-03T21:52:16.351082Z","iopub.status.idle":"2025-03-03T21:52:16.355373Z","shell.execute_reply.started":"2025-03-03T21:52:16.351064Z","shell.execute_reply":"2025-03-03T21:52:16.354664Z"},"id":"eQm4fr9GXylt","outputId":"9bd53022-bf70-4ad7-ca1d-6214def7e668","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Build the model\n","metadata":{"id":"1wwv_K__Xylt"}},{"cell_type":"code","source":"#Pretrained model DermNet\nbase_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n\n# Freeze the base model\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# layers for fine-tuning\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(train_df['label'].nunique(), activation='softmax')(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile the model\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\nmodel.summary()","metadata":{"id":"CQJ_T8nMXylt","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T21:52:16.356075Z","iopub.execute_input":"2025-03-03T21:52:16.356335Z","iopub.status.idle":"2025-03-03T21:52:16.507515Z","shell.execute_reply.started":"2025-03-03T21:52:16.356312Z","shell.execute_reply":"2025-03-03T21:52:16.506669Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unfreeze\nbase_model.trainable = True\n\nfor layer in base_model.layers[:-10]:  \n    layer.trainable = False\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Fine-tune the model\nhistory_fine_tune = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=5,\n    callbacks=[early_stopping]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# IGNORE \n\n# Import pretrained dataset ddi_model\n!git clone https://github.com/DDI-Dataset/DDI-Code.git\n\n# Changing directory \n%cd DDI-Code\n\nfrom ddi_model import load_model\n\npretrained_model = load_model('HAM10000')\n\n# Freeze Base Layers\nfor param in pretrained_model.parameters():\n    param.requires_grad = False\n\n# Unfreeze layers \nfor param in pretrained_model.fc.parameters():\n    param.requires_grad = True\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(pretrained_model.parameters(), lr=0.0001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Train the Model\n","metadata":{"id":"rYXsKeFKXylu"}},{"cell_type":"code","source":"# TODO: Train your model here.\n\n# Data Augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    directory='/kaggle/input/bttai-ajl-2025/train/train/',\n    x_col='file_path',\n    y_col='label',\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='sparse',\n    subset='training'\n)\n\nval_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    directory='/kaggle/input/bttai-ajl-2025/train/train/',\n    x_col='file_path',\n    y_col='label',\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='sparse',\n    subset='validation'\n)","metadata":{"id":"wLVAGVkbXylu","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T21:52:16.508253Z","iopub.execute_input":"2025-03-03T21:52:16.508536Z","iopub.status.idle":"2025-03-03T22:02:45.806702Z","shell.execute_reply.started":"2025-03-03T21:52:16.508513Z","shell.execute_reply":"2025-03-03T22:02:45.806052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=10,\n    callbacks=[early_stopping]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Make Predictions on Test Data","metadata":{"id":"z_T8IkRhXylu"}},{"cell_type":"code","source":"# 6. Make Predictions on Test Data\ndef preprocess_test_data(test_df, directory):\n    \"\"\"\n    Template for loading and preprocessing test images.\n    \"\"\"\n    # TODO: create a generator for the test set here.\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    test_generator = test_datagen.flow_from_dataframe(\n        test_df,\n        directory=directory,\n        x_col='md5hash',\n        y_col=None,\n        target_size=(128, 128),\n        batch_size=32,\n        class_mode=None,\n        shuffle=False\n    )\n    return test_generator\n\n# Load test data\ntest_dir = '/kaggle/input/bttai-ajl-2025/test/test/'\ntest_generator = preprocess_test_data(test_df, test_dir)","metadata":{"execution":{"iopub.status.busy":"2025-03-03T22:02:45.807358Z","iopub.execute_input":"2025-03-03T22:02:45.807565Z","iopub.status.idle":"2025-03-03T22:02:45.811418Z","shell.execute_reply.started":"2025-03-03T22:02:45.807548Z","shell.execute_reply":"2025-03-03T22:02:45.810606Z"},"id":"GF_dTxP2Xylu","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Generate Predictions","metadata":{"id":"xpP0S2abXylu"}},{"cell_type":"code","source":"# TODO\n# Generate predictions based on the trained model\n# Then, save the predictions into a CSV file for submission\n\npredictions = model.predict(test_generator)\npredicted_classes = predictions.argmax(axis=1)\n\n# Create submission file\nsubmission = pd.DataFrame({'md5hash': test_df['md5hash'], 'label': predicted_classes})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Predictions saved to submission.csv\")\n","metadata":{"id":"SFbfnjujXylu","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T22:02:48.286549Z","iopub.execute_input":"2025-03-03T22:02:48.286844Z","iopub.status.idle":"2025-03-03T22:02:57.523779Z","shell.execute_reply.started":"2025-03-03T22:02:48.286807Z","shell.execute_reply":"2025-03-03T22:02:57.522942Z"}},"outputs":[],"execution_count":null}]}